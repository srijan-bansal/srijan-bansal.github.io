@article{bansal2023fewshot,
title={Few-shot Unified Question Answering: Tuning Models or Prompts?}, 
author={Srijan Bansal and Semih Yavuz and Bo Pang and Meghana Bhat and Yingbo Zhou},
year={2023},
arXiv="2305.14569",
journal={arXiv preprint arXiv:2305.14569},
abbr="arxiv",
abstract = {Question-answering (QA) tasks often investigate specific question types, knowledge domains, or reasoning skills, leading to specialized models catering to specific categories of QA tasks. While recent research has explored the idea of unified QA models, such models are usually explored for high-resource scenarios and require re-training to extend their capabilities. To overcome these drawbacks, the paper explores the potential of two paradigms of tuning, model, and prompts, for unified QA under a low-resource setting. The paper provides an exhaustive analysis of their applicability using 16 QA datasets, revealing that prompt tuning can perform as well as model tuning in a few-shot setting with a good initialization. The study also shows that parameter-sharing results in superior few-shot performance, simple knowledge transfer techniques for prompt initialization can be effective, and prompt tuning achieves a significant performance boost from pre-training in a low-resource regime. The research offers insights into the advantages and limitations of prompt tuning for unified QA in a few-shot setting, contributing to the development of effective and efficient systems in low-resource scenarios.},
}

@inproceedings{bansal-etal-2022-pro,
    title = "{PRO}-{CS} : An Instance-Based Prompt Composition Technique for Code-Switched Tasks",
    author = "Bansal, Srijan  and
      Tripathi, Suraj  and
      Agarwal, Sumit  and
      Mitamura, Teruko  and
      Nyberg, Eric",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.698",
    pages = "10243--10255",
    abbr="EMNLP",
    poster = "procs_poster.pdf",
    code="https://github.com/srijan-bansal/PRO-CS",    
    abstract = "Code-switched (CS) data is ubiquitous in today's globalized world, but the dearth of annotated datasets in code-switching poses a significant challenge for learning diverse tasks across different language pairs. Parameter-efficient prompt-tuning approaches conditioned on frozen language models have shown promise for transfer learning in limited-resource setups. In this paper, we propose a novel instance-based prompt composition technique, PRO-CS, for CS tasks that combine language and task knowledge. We compare our approach with prompt-tuning and fine-tuning for code-switched tasks on 10 datasets across 4 language pairs. Our model outperforms the prompt-tuning approach by significant margins across all datasets and outperforms or remains at par with fine-tuning by using just 0.18{\%} of total parameters. We also achieve competitive results when compared with the fine-tuned model in the low-resource cross-lingual and cross-task setting, indicating the effectiveness of our approach to incorporate new code-switched tasks.",
}

@inproceedings{bansal-etal-2022-r3,
    title = "R3 : Refined Retriever-Reader pipeline for Multidoc2dial",
    author = "Bansal, Srijan  and
      Tripathi, Suraj  and
      Agarwal, Sumit  and
      Gururaja, Sireesh  and
      Veerubhotla, Aditya Srikanth  and
      Dutt, Ritam  and
      Mitamura, Teruko  and
      Nyberg, Eric",
    booktitle = "Proceedings of the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.dialdoc-1.17",
    doi = "10.18653/v1/2022.dialdoc-1.17",
    abbr="ACL Dialdoc",
    poster = "Dialdoc_poster.pdf",
    code="https://github.com/srijan-bansal/R3_Mulltidoc2dial",    
    pages = "148--154",
    abstract = "In this paper, we present our submission to the DialDoc shared task based on the MultiDoc2Dial dataset. MultiDoc2Dial is a conversational question answering dataset that grounds dialogues in multiple documents. The task involves grounding a user{'}s query in a document followed by generating an appropriate response. We propose several improvements over the baseline{'}s retriever-reader architecture to aid in modeling goal-oriented dialogues grounded in multiple documents. Our proposed approach employs sparse representations for passage retrieval, a passage re-ranker, the fusion-in-decoder architecture for generation, and a curriculum learning training paradigm. Our approach shows a 12 point improvement in BLEU score compared to the baseline RAG model.",
}


@inproceedings{10.1145/3465336.3475118,
author = {Bansal, Srijan and Garimella, Vishal and Suhane, Ayush and Mukherjee, Animesh},
title = {Debiasing Multilingual Word Embeddings: A Case Study of Three Indian Languages},
year = {2021},
isbn = {9781450385510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465336.3475118},
doi = {10.1145/3465336.3475118},
abstract = {In this paper, we advance the current state-of-the-art method for debiasing monolingual word embeddings so as to generalize well in a multilingual setting. We consider different methods to quantify bias and different debiasing approaches for monolingual as well as multilingual settings. We demonstrate the significance of our bias-mitigation approach on downstream NLP applications. Our proposed methods establish the state-of-the-art performance for debiasing multilingual embeddings for three Indian languages - Hindi, Bengali, and Telugu in addition to English. We believe that our work will open up new opportunities in building unbiased downstream NLP applications that are inherently dependent on the quality of the word embeddings used.},
booktitle = {Proceedings of the 32nd ACM Conference on Hypertext and Social Media},
pages = {27â€“34},
numpages = {8},
keywords = {multilingual gender debiasing, debiasing indian languages},
location = {Virtual Event, USA},
abbr="ACM Hypertext",
arXiv="2107.10181",
slides = "debias_slides.pdf",
code="https://github.com/srijan-bansal/Debiasing-Multilingual-Word-Embeddings-A-Case-Study-of-Three-Indian-Languages",
series = {HT '21}
}


@inproceedings{bansal-etal-2020-code,
    title = "Code-Switching Patterns Can Be an Effective Route to Improve Performance of Downstream {NLP} Applications: A Case Study of Humour, Sarcasm and Hate Speech Detection",
    author = "Bansal, Srijan  and
      Garimella, Vishal  and
      Suhane, Ayush  and
      Patro, Jasabanta  and
      Mukherjee, Animesh",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.96",
    doi = "10.18653/v1/2020.acl-main.96",
    pages = "1018--1023",
    abbr="ACL",
    code="https://github.com/srijan-bansal/ACL20-Code-switching-patterns",    
    abstract = "In this paper, we demonstrate how code-switching patterns can be utilised to improve various downstream NLP applications. In particular, we encode various switching features to improve humour, sarcasm and hate speech detection tasks. We believe that this simple linguistic observation can also be potentially helpful in improving other similar NLP applications.",
}


@inproceedings{patro-etal-2019-deep,
    title = "A deep-learning framework to detect sarcasm targets",
    author = "Patro, Jasabanta  and
      Bansal, Srijan  and
      Mukherjee, Animesh",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1663",
    doi = "10.18653/v1/D19-1663",
    pages = "6336--6342",
    abbr="EMNLP",
    poster = "EMNLP2019_Sarcam_Poster.pdf",
    code="https://github.com/srijan-bansal/Sarcasm_Target_Detection-EMNLP-",
    abstract = "In this paper we propose a deep learning framework for sarcasm target detection in predefined sarcastic texts. Identification of sarcasm targets can help in many core natural language processing tasks such as aspect based sentiment analysis, opinion mining etc. To begin with, we perform an empirical study of the socio-linguistic features and identify those that are statistically significant in indicating sarcasm targets (p-values in the range(0.05,0.001)). Finally, we present a deep-learning framework augmented with socio-linguistic features to detect sarcasm targets in sarcastic book-snippets and tweets.We achieve a huge improvement in the performance in terms of exact match and dice scores compared to the current state-of-the-art baseline.",
}

@inproceedings{10.1145/3297001.3297047,
author = {Santosh, T. Y.S.S. and Bansal, Srijan and Saha, Avirup},
title = {Can Siamese Networks Help in Stance Detection?},
year = {2019},
isbn = {9781450362078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297001.3297047},
doi = {10.1145/3297001.3297047},
abstract = {An important component of fake news detection is to evaluate the stance, different news sources take towards the assertion. Automatic stance detection, would facilitate the process of fact checking. In this paper, we present our stance detection system which comprises of siamese adaptation of Long Short Term Memory (LSTM) networks augmented with an attention mechanism, as siamese adaptation forces the LSTM to entirely capture the semantic differences during training, rather than supplementing the network with a more complex learner that can help resolve shortcomings in the learned representations. Our experiments on a public benchmark dataset, FakeNewsChallenge (FNC), demonstrate the effectiveness of our approach. It focuses on classifying the stance of a news article body relative to a headline as agree, disagree, discuss, or unrelated.},
booktitle = {Proceedings of the ACM India Joint International Conference on Data Science and Management of Data},
pages = {306â€“309},
numpages = {4},
abbr="CoDS-COMAD",
keywords = {stance detection, siamese networks},
location = {Kolkata, India},
series = {CODS-COMAD '19}
}
